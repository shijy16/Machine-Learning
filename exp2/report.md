# Machine Learning Exp2 Report

2016011395 石景宜

## 一、 实验背景

+ 集成学习：使用一系列学习器进行学习，并使用某种规则把各个学习结果进行整合从而获得比单个学习器更好的学习效果的一种机器学习方法。
+ `bootstrapping`：在大小为S的数据集上进行S次有放回的抽样，建立新的训练集。由于会有很多重复出现的样本，新的训练集中约包含原有数据集63.2%的数据。
+ `Bagging`：通过bootstrapping多次在原有数据集中抽样生成n个新的数据集，然后使用同一种弱学习器分别进行n次学习得到n个学习器，由这n个学习器在测试集上进行预测，最终结果为这n个学习器预测结果的平均值。
+  `AdaBoosting`:每次使用全部的样本，每轮训练改变样本的权重。下一轮训练的目标是找到一个函数f 来拟合上一轮的残差。当残差足够小或者达到设置的最大迭代次数则停止。Boosting会减小在上一轮训练正确的样本的权重，增大错误样本的权重。

## 二、 实验任务

+ 基础任务
  + 使用两种集成学习方法（`AdaBoosting`、`Bagging`)和两种分类器（SVM和决策树）完成实验。
+ 拓展任务
  + 使用其他分类器。
  + 分析不同feature的效果。
  + 调整集成学习算法的参数，分析他们对结果的影响。
  + 使用其他方法来达到更好的效果。

## 三、实验设计

### Feature 选取和处理

本次实验feature一共有`reviewerID，asin，reviewText，overall，votes_all，votes_up`，要在训练中让他们起到作用，需要对他们进行进一步处理。

#### 1. `reviewText` 

评论文本是分类的一个重要依据，可以按评论文本的以下三个特性作为feature进行训练：

+ 文本单词数：文本包含英文单词的个数。
+ 文本长度：`len(reviewText)`。
+ 文本词向量：文本中包含不同的词，可以将文本转换为词向量作为训练数据进行训练。

现对各个特性在两个label情况下的差异性进行探究，以选取差异最大的特性来训练。

##### 文本单词数

![](D:\code\Mechine-Learning\exp2\Figure_1.png)

上图中横轴为词数量，纵轴为概率。从图中可以看出，两种文本词数量都集中在0-600之间，label为0的文本词数量为75处达到峰值且分布较为集中，label为1的文本词数量在词数量为190处达到峰值，分布较为分散。

这可以作为一个feature，但从图中看出两种文本的词数量差异并不显著，因此该feature作用不会太大。

##### 文本长度

![](D:\code\Mechine-Learning\exp2\Figure_2.png)

文本长度特征和文本单词数分布情况相似，两中文本具有分布差异但同样不够显著。

##### 文本词向量

记$ P(w_i|label_i) $为单词$w_i$在label为$label_i$的`reviewText`中出现的概率。下图为$ ||P(w_i|0) - P(w_i|1) ||  $最大的前200词的在两种编辑文本中出现的词频对比图。其中，红色为在label为1中的词频，蓝色为label为0中的词频。

![](D:\code\Mechine-Learning\exp2\Figure_3.png)

可以看出，两者词频有差距，但是差距不大。

>  因此`reviewText`在两个label中各种feature差距不大。选用贝叶斯方法和决策树可能会较好。

### 2. `reviewerID`

根据常识判断，每个人对商品的评价会偏向于高质量或者低质量两个方面，因此`reviewerID`是分类的重要依据。实际上,$ reviewerID_i$ 在两类中出现概率之差最大的200个分布如下（红色是$ reviewerID_i$出现在label为1中的概率，蓝色是出现在label为0中的概率）：

![](D:\code\Mechine-Learning\exp2\Figure_4.png)

但是，`reviewerID`是一个字符串，在SVM中